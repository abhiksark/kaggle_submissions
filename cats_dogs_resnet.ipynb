{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats and dogs cnn",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/abhiksark/kaggle_submissions/blob/master/cats_dogs_resnet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "rUsB32S0A64c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZLMfElvCXrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e2b8578e-fb85-4df3-a492-85988bca3f05"
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/.kaggle\n",
        "#!mv /content/.kaggle kaggle.json\n",
        "#!ls\n",
        "#!chmod 600 ~ kaggle.json\n",
        "!mv kaggle.json /content/.kaggle\n",
        "!rm -rf *\n",
        "!ls /content/.kaggle/\n",
        "!chmod 600 ~ /content/.kaggle/kaggle.json\n"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/.kaggle’: File exists\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e9HaJoGZCr04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "bf7cba4b-b3c1-4e99-8493-20bb85c1e158"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats -p datalab\n",
        "!ls  datalab/\n"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.6)\r\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\r\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\r\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\r\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "sampleSubmission.csv: Downloaded 87KB of 87KB\n",
            "\n",
            "train.zip: Downloaded 543MB of 543MB\n",
            "sampleSubmission.csv  test1.zip  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hmdu5AghCtef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip datalab/test1.zip\n",
        "!unzip datalab/train.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxdyJBWBCv0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!ls\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDIP2_mnCxkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca90e112-3031-4918-f2e1-5a90b4303fc6"
      },
      "cell_type": "code",
      "source": [
        "import os, cv2, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VDIIAfYRFpeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbfcaaa9-ad4c-4781-dea7-17058cc42b6b"
      },
      "cell_type": "code",
      "source": [
        "train_dir = 'train/'\n",
        "test_dir = 'test1/'\n",
        "train_images_dogs_cats = [train_dir+i for i in os.listdir(train_dir)] # use this for full dataset\n",
        "test_images_dogs_cats = [train_dir+i for i in os.listdir(train_dir)]\n",
        "\n",
        "len(train_images_dogs_cats)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QzQyLACPC1kx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4fb4dedf-ba3b-4d64-9b3b-d96641973cc1"
      },
      "cell_type": "code",
      "source": [
        "!mkdir train/cat/\n",
        "!mkdir train/dog/\n",
        "!mkdir val/\n",
        "!mkdir val/cat/\n",
        "!mkdir val/dog/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train/cat/’: File exists\n",
            "mkdir: cannot create directory ‘train/dog/’: File exists\n",
            "mkdir: cannot create directory ‘val/’: File exists\n",
            "mkdir: cannot create directory ‘val/cat/’: File exists\n",
            "mkdir: cannot create directory ‘val/dog/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gn5en1ZyC5Zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d0976fec-44da-4108-d7ed-4b19deae916d"
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "src_dir = \"train/\"\n",
        "for train_dir in train_images_dogs_cats[:20000]:\n",
        "      #print(train_dir)\n",
        "      train_dir_header = train_dir.split(\"/\")\n",
        "      image_header= train_dir_header[1].split(\".\") \n",
        "      img_class = image_header[0]\n",
        "      os.rename(train_dir,src_dir + img_class + \"/\" + train_dir_header[1] )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-41a534d4f7b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrc_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_images_dogs_cats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0;31m#print(train_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mtrain_dir_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimage_header\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dir_header\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images_dogs_cats' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5tW0_-z_C63_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e531892c-50b7-4a50-bceb-4cedaae77b9f"
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "src_dir = \"./val/\"\n",
        "for train_dir in train_images_dogs_cats[20000:]:\n",
        "      #print(train_dir)\n",
        "      train_dir_header = train_dir.split(\"/\")\n",
        "      image_header= train_dir_header[1].split(\".\") \n",
        "      img_class = image_header[0]\n",
        "      os.rename(train_dir, src_dir + img_class + \"/\" + train_dir_header[1] )\n",
        "\n",
        "      \n",
        "      "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3cc43934774a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msrc_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./val/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_images_dogs_cats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0;31m#print(train_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mtrain_dir_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimage_header\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dir_header\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images_dogs_cats' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ULovOb20DKiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "617e0f5c-a725-43e5-cb51-8e846ec62930"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_dir = './train/'\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        " \n",
        "#train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
        "#train_labels = np.zeros(shape=(nTrain))\n",
        " \n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "  \n",
        "    train_dir,\n",
        "    target_size=(200, 200),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ikcMM9wVDOyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dbdd755-1a89-4478-b08c-af991ca9faa8"
      },
      "cell_type": "code",
      "source": [
        "val_dir = './val/'\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        " \n",
        "#train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
        "#train_labels = np.zeros(shape=(nTrain))\n",
        " \n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(200,200),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "37HuiWS20JMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vap7nh3DSTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of convolutional filters to use\n",
        "nb_filters = 15\n",
        "# size of pooling area for max pooling\n",
        "nb_pool = 2\n",
        "# convolution kernel size\n",
        "nb_conv = 4\n",
        "\n",
        "\n",
        "# number of output classes\n",
        "nb_classes = 5\n",
        "# number of epochs to train\n",
        "nb_epoch = 64\n",
        "\n",
        "img_rows, img_cols = 224,224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SY2ukNyBgaKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers, Input\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFHkNHrgg7wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model(learn_rate=0.001, decay=0.1, trainable=False):\n",
        "    \"\"\"Get ResNet50 model.\"\"\"\n",
        "    main_model = ResNet50(include_top=False, input_tensor=Input(\n",
        "        shape=(224, 224, 3)))\n",
        "\n",
        "    main_model.trainable = trainable\n",
        "    for layer in main_model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=main_model.output_shape[1:]))\n",
        "    # top_model.add(Dense(128, activation='relu'))\n",
        "    top_model.add(Dropout(0.3))\n",
        "    top_model.add(Dense(17, activation='sigmoid'))\n",
        "    model = Model(inputs=main_model.input,\n",
        "                  outputs=top_model(main_model.output))\n",
        "\n",
        "    opt = optimizers.Adam(lr=learn_rate, decay=decay)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=[fbeta, 'accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wD-3asCmRP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "979d0940-ddaa-403f-c545-383121034b35"
      },
      "cell_type": "code",
      "source": [
        "number_of_batches =8\n",
        "counter = 0\n",
        "main_model = ResNet50(include_top=False, input_tensor=Input(\n",
        "        shape=(224, 224, 3)))\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  horizontal_flip=True)\n",
        "\n",
        "x_batch = next(datagen.flow_from_directory(\n",
        "  val_dir,\n",
        "  target_size=(224, 224),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='binary'))\n",
        "\n",
        "print(type(x_batch[1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ginTpm1qkBHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9292985e-5cf4-43fe-e261-1f29d0e269e1"
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "process_target = True\n",
        "\n",
        "flow_val=datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "flow_train=datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "counter =0\n",
        "\n",
        "def batch_generator_val(datagen,flow_val):\n",
        "  number_of_batches =8\n",
        "  global counter\n",
        "  while True:\n",
        "    counter = counter +1\n",
        "    x_batch = next(flow_val,counter)\n",
        "    x = main_model.predict(x_batch[0])\n",
        "    y = x_batch[1]\n",
        "    res_batch = (x,y)\n",
        "    yield res_batch\n",
        "  \n",
        "def batch_generator_train(datagen,flow_train):\n",
        "  number_of_batches =8  \n",
        "  global counter \n",
        "  while True:\n",
        "    x_batch = next(flow_train,counter)\n",
        "    x = main_model.predict(x_batch[0])\n",
        "    y = x_batch[1]\n",
        "    res_batch = (x,y)\n",
        "    yield res_batch\n",
        "\n",
        "   \n",
        "    \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYhBfqoOgQCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_generator = batch_generator_val(datagen,flow_val)\n",
        "train_generator = batch_generator_train(datagen,flow_train)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSSvGsGpqFCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e657d06-a1a6-4c02-e00e-707c7126fce3"
      },
      "cell_type": "code",
      "source": [
        "next(val_generator)[0].shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 1, 1, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "iMzcmF9shJ0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Training model...')\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=4, verbose=1),\n",
        "             ModelCheckpoint(model_weights_path, monitor='val_loss',\n",
        "                             save_best_only=True, verbose=0)]\n",
        "\n",
        "steps_per_epoch_fit = np.ceil(len(fit_index) / batch_size)\n",
        "steps_per_epoch_val = np.ceil(len(val_index) / batch_size)\n",
        "\n",
        "fit_generator = batch_generator(train_dir,\n",
        "                                df_train.iloc[fit_index],\n",
        "                                label_map,\n",
        "                                batch_size=batch_size,\n",
        "                                number_of_batches=steps_per_epoch_fit,\n",
        "                                data_gen_args=data_gen_args_fit,\n",
        "                                seed=seed)\n",
        "\n",
        "val_generator = batch_generator(train_dir,\n",
        "                                df_train.iloc[val_index],\n",
        "                                label_map,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=False,\n",
        "                                number_of_batches=steps_per_epoch_val,\n",
        "                                data_gen_args=data_gen_args_val)\n",
        "try:\n",
        "    model.fit_generator(generator=fit_generator,\n",
        "                        steps_per_epoch=steps_per_epoch_fit,\n",
        "                        epochs=epochs,\n",
        "                        verbose=1,\n",
        "                        validation_data=val_generator,\n",
        "                        validation_steps=steps_per_epoch_val,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHJ48awEKwVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "1be46c3c-b77c-4c27-a6cc-7f31d86919a0"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.9999, epsilon=1e-07, decay=0.00001, amsgrad=False)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
        "                        border_mode='valid',\n",
        "                        input_shape=(img_cols, img_rows, 3)))\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "model.add(Convolution2D(nb_filters, nb_conv))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+1, nb_pool+1)))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "convout2 = Activation('relu')\n",
        "model.add(convout2)\n",
        "model.add(Convolution2D(nb_filters, nb_conv-2, nb_conv-2))\n",
        "model.add(MaxPooling2D(pool_size=(nb_pool+2, nb_pool+2)))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(50))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (4, 4), input_shape=(224, 224,..., padding=\"valid\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (2, 2))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OpLbI1yxL-CG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "1e20e6bd-7b08-4e1c-dd3b-b2974d9f8d31"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 221, 221, 15)      735       \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 221, 221, 15)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 218, 218, 15)      3615      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 72, 72, 15)        0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 72, 72, 15)        0         \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 72, 72, 15)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 71, 71, 15)        915       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 17, 17, 15)        0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 17, 17, 15)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 4335)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 500)               2168000   \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 50)                25050     \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 2,198,366\n",
            "Trainable params: 2,198,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IcMq1mi8dVa_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import keras\n",
        "\n",
        "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.9999, epsilon=1e-07, decay=0.00001, amsgrad=False)\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_shape=(1,1,2048)))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXfiMYycK0N_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a7a647bf-c2ab-4383-9b01-5e9e2c460321"
      },
      "cell_type": "code",
      "source": [
        "hist_plot = model.fit_generator(train_generator, steps_per_epoch=90, workers=0 ,epochs=50, validation_data=val_generator, validation_steps=30, use_multiprocessing=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "90/90 [==============================] - 32s 353ms/step - loss: 0.7766 - acc: 0.5056 - val_loss: 0.7073 - val_acc: 0.4583\n",
            "Epoch 2/50\n",
            "36/90 [===========>..................] - ETA: 13s - loss: 0.7177 - acc: 0.5833"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nn6Au51PK6pe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "0import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(hist_plot.history['acc'])\n",
        "plt.plot(hist_plot.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(hist_plot.history['loss'])\n",
        "plt.plot(hist_plot.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMpo4OyebXCs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(hist_plot.history['acc'])\n",
        "plt.plot(hist_plot.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(hist_plot.history['loss'])\n",
        "plt.plot(hist_plot.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QaRQa5ljVQuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "test_images_dogs_cats = [test_dir+i for i in os.listdir(test_dir)]\n",
        "\n",
        "x=0\n",
        "prediction_probabilities = []\n",
        "name = []\n",
        "i=0\n",
        "img_width,img_height = 200,200\n",
        "for image in test_images_dogs_cats:\n",
        "  x=(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
        "  x = np.array(x,dtype='float32')\n",
        "  x = x * 1./255\n",
        "  x= np.reshape(x,(1,200, 200, 3))\n",
        "  print(name)\n",
        "  name.append(int((image.split(\"/\")[1]).split(\".\")[0]))\n",
        "  prediction_probabilities.append(model.predict(x, verbose=1))\n",
        "  \n",
        "  print(model.predict(x, verbose=1))\n",
        "  i=i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMpnDbUGsaE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_probabilities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XbCd2yJrHZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "solution = pd.DataFrame({\"id\": name, \"label\":prediction_probabilities})\n",
        "head = solution.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OSfIhrKrWNq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "solution.to_csv(\"dogsVScats.csv\", index = False)\n",
        "uploaded = drive.CreateFile({'title': 'dogsVScats.csv'})\n",
        "uploaded.SetContentFile('dogsVScats.csv')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrgKlfxfrZbW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "image  =  test_images_dogs_cats[8889]\n",
        "img=mpimg.imread(image)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "x=(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
        "print(x[0].shape)\n",
        "x = np.array(x,dtype='float32')\n",
        "\n",
        "x = x * 1./255\n",
        "x= np.reshape(x,(1,200, 200, 3))\n",
        "\n",
        "print(model.predict(x, verbose=1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ru7-xeMjt3ni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import preprocess_input, ResNet50\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers, Input\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfKxZ9ssznA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Fine tuning ResNet50 with batch generator.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def batch_generator(img_dir_path, df, label_map, batch_size=32, shuffle=True,\n",
        "                    seed=2017, target_image_size=(224, 224),\n",
        "                    process_target=True, number_of_batches=None,\n",
        "                    add_seed_shuffle=True, data_gen_args={}, cv2_read=True,\n",
        "                    preprocess_unit=False):\n",
        "    \"\"\"Batch generator for keras model.\"\"\"\n",
        "    if number_of_batches is None:\n",
        "        number_of_batches = np.ceil(df.shape[0] / batch_size)\n",
        "        print(number_of_batches)\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(seed)\n",
        "        df = df.sample(frac=1)\n",
        "\n",
        "    while True:\n",
        "        if process_target:\n",
        "            y_batch = []\n",
        "\n",
        "        idx_start = batch_size * counter\n",
        "        idx_end = batch_size * (counter + 1)\n",
        "        x_batch = []\n",
        "\n",
        "        for f, tags in df.iloc[idx_start:idx_end].values:\n",
        "            img_path = os.path.join(img_dir_path, '{}.jpg'.format(f))\n",
        "            if cv2_read:\n",
        "                img = cv2.imread(img_path)\n",
        "                x = cv2.resize(img, target_image_size)\n",
        "            else:\n",
        "                img = image.load_img(img_path, target_size=target_image_size)\n",
        "                x = image.img_to_array(img)\n",
        "\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "            if preprocess_unit:\n",
        "                x = preprocess_input(x)\n",
        "\n",
        "            x_batch.append(x)\n",
        "\n",
        "            if process_target:\n",
        "                targets = np.zeros(17)\n",
        "                for t in tags.split(' '):\n",
        "                    targets[label_map[t]] = 1\n",
        "                y_batch.append(targets)\n",
        "\n",
        "        x_batch = np.concatenate(x_batch)\n",
        "\n",
        "        datagen = ImageDataGenerator(**data_gen_args)\n",
        "        datagen.fit(x_batch)\n",
        "        x_batch = next(datagen.flow(x_batch, shuffle=False))\n",
        "\n",
        "        counter += 1\n",
        "        if process_target:\n",
        "            yield x_batch, np.array(y_batch)\n",
        "        else:\n",
        "            yield x_batch\n",
        "\n",
        "        if (counter == number_of_batches):\n",
        "            if shuffle:\n",
        "                if add_seed_shuffle:\n",
        "                    np.random.seed(seed + 1)\n",
        "                df = df.sample(frac=1)\n",
        "            counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBAuu7YjtbHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "911NN8Bntbsa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}